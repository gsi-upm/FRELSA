{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e3998f",
   "metadata": {},
   "source": [
    "# Notebook for the creation of the FRELSA dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbfa589",
   "metadata": {},
   "source": [
    "Department of Telematic Engineering Systems, Universidad Politécnica de Madrid, © Matteo Leghissa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc377a",
   "metadata": {},
   "source": [
    "To properly run this notebook one should have the data from wave 5 and wave 6 of the ELSA (Englidh Longitudinal Study of Ageing) study [https://www.elsa-project.ac.uk/].\n",
    "\n",
    "A frailty variable based on the FFP (Fried's Frailty Phenotype) definition is created starting from wave 6 data.\n",
    "The best variables for the classification problem of said frailty label are selected from wave 5 and 6 using the MULTISurf algorithm.\n",
    "Seven ML arcitectures are then trained on the classification task (detection with wave 6 and prefiction with wave 5).\n",
    "\n",
    "Let us start by importing all necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa4ab021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split, StratifiedKFold, cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skrebate import multisurf\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from preprocess import load_data, preprocess_frailty_db, add_fried_w6, load_w6, load_w5\n",
    "from models import get_cv_metrics\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c870a1",
   "metadata": {},
   "source": [
    "## Computation of the Fried Frailty Phenotype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba86a79",
   "metadata": {},
   "source": [
    "Let us open wave 6 data (both core data and nurse visit data), and merge them in a single dataframe.\n",
    "\n",
    "Now we can compute the frailty level for the wave 6 patients using the merged dataframe.\n",
    "We drop all the varaibles we ued for the computation, and all the patients which frailty level could not be computed.\n",
    "\n",
    "The frailty is computed using an adaptation of the FFP definition, as described in the following table:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2000a4e3",
   "metadata": {},
   "source": [
    "![FFPtable](img/FFP-table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4728e569",
   "metadata": {},
   "source": [
    "We then save the dataframe with the new frailty variable added, to avoid repeating this step in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92cb7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_data_path = \"data/raw/wave_6_elsa_data_v2.tab\"\n",
    "nurse_data_path = \"data/raw/wave_6_elsa_nurse_data_v2.tab\"\n",
    "frelsa, ffp = add_fried_w6(elsa_w6_merged=load_w6(core_data_path=core_data_path, nurse_data_path=nurse_data_path),\n",
    "                     drop_columns=True, drop_rows=True)\n",
    "frelsa[\"FFP\"] = ffp\n",
    "frelsa.to_csv('data/raw/wave_6_frailty_FFP_data.tab', sep='\\t', index_label='idauniq', quoting=3, escapechar='\\\\')\n",
    "frelsa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff12f6",
   "metadata": {},
   "source": [
    "## Features selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2864e552",
   "metadata": {},
   "source": [
    "We can now load the wave 6 data we just saved, with its frailty label.\n",
    "\n",
    "We can also load wave 5 data, and filter it to only keep the wave 5 patients who were still present in wave 6 and had their frailty level computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b02965",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w6, y_w6 = load_data(file_name=\"wave_6_frailty_FFP_data.tab\", folder_path=\"data/raw/\", target_variable=\"FFP\",\n",
    "                     index=\"idauniq\")\n",
    "data_file_w5 = \"wave_5_elsa_data_v4.tab\"\n",
    "X_w5 = load_w5(core_data_path=\"data/raw/\" + str(data_file_w5), index_col='idauniq', acceptable_features=None,\n",
    "            acceptable_idauniq=X_w6.index, drop_frailty_columns=None)\n",
    "y_w5 = y_w6.loc[X_w5.index]\n",
    "y_w5.sort_index(inplace=True)\n",
    "X_w5.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d6599",
   "metadata": {},
   "source": [
    "We then preprocess both wave 5 and 6 data to scale the values and perform feature selection using the MultiSURF logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dd0ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w6, y_w6 = preprocess_frailty_db(X=X_w6, y=y_w6, replace_missing_value=True, regex_list=None,\n",
    "                                   replace_negatives=np.nan, replace_nan=None, rm_constant_features=True, min_max=True, group_frailty=True)\n",
    "X_w5, y_w5 = preprocess_frailty_db(X=X_w5, y=y_w5, replace_missing_value=True, regex_list=None,\n",
    "                                   replace_negatives=np.nan, replace_nan=None, rm_constant_features=True,\n",
    "                                   min_max=True, group_frailty=True)\n",
    "\n",
    "n_features=50\n",
    "multisurf_feature_selection(X=X_w6, y=y_w6, n_features=n_features, discrete_threshold=20, n_jobs=-1, save_features=True,\n",
    "                            file_path=\"data/best_features/wave_6_features.tab\")\n",
    "multisurf_feature_selection(X=X_w5, y=y_w5, n_features=n_features, discrete_threshold=20, n_jobs=-1, save_features=True,\n",
    "                            file_path=\"data/best_features/wave_5_features.tab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6803f2ea",
   "metadata": {},
   "source": [
    "This process might be costly and take a long time, especially if we do not have many CPUs or GPUs available.\n",
    "\n",
    "We have saved the best features names in a file, so that we will not have to repeat this process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df0fbe0",
   "metadata": {},
   "source": [
    "## Models training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf58594",
   "metadata": {},
   "source": [
    "Let us define in a dictionary the different classifiers we want to train, with all the hyperparameters we want to try out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\"SVM_linear\": [SVC(kernel='linear'), {'C': [0.1, 1, 10]}],\n",
    "               \"SVM_rbf\": [SVC(kernel='rbf'), {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1]}],\n",
    "               \"MLP\": [MLPClassifier(),\n",
    "                       {'hidden_layer_sizes': [(100, 50,), (100, 75, 25,)],\n",
    "                        'activation': ['relu', 'tanh'], 'alpha': [0.001, 0.0001], 'max_iter': [2000]}],\n",
    "               \"DT\": [DecisionTreeClassifier(), {'max_depth': [5, 10, 20]}],\n",
    "               \"RF\": [RandomForestClassifier(), {'max_depth': [5, 10, 20], 'n_estimators': [20, 50, 100]}],\n",
    "               \"LR\": [LogisticRegression(), {'C': [0.1, 1, 10], 'max_iter': [2000]}]\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d35530",
   "metadata": {},
   "source": [
    "### Detection models (wave 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ac7872",
   "metadata": {},
   "source": [
    "Now we can read the file we just saved with the best features, train the models specified in the dictionary above, including possibly a Voting Classifier.\n",
    "\n",
    "We then save the results and if needed the models in pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd952a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X_w6, y_w6\n",
    "\n",
    "# Load selected variables\n",
    "prediction_multisurf_variables = pd.read_csv(\"data/best_features/wave_6_features.tab\", sep='\\t', \n",
    "                                             escapechar='\\\\')['0'].tolist()\n",
    "X = X.loc[:, prediction_multisurf_variables]\n",
    "\n",
    "# Eliminate specific repeated features\n",
    "X.drop(list(X.filter(regex = 'ff.*')), axis = 1, inplace = True)\n",
    "\n",
    "# Select the best_grid_search features\n",
    "scoring = ['accuracy', 'precision_macro', 'f1_macro', 'recall_macro']\n",
    "folds = 10\n",
    "seed = 10\n",
    "epochs = 1000\n",
    "\n",
    "# Train models and save results\n",
    "saved_model_path = \"data/models/detection/model\"\n",
    "saved_results_path = \"data/metrics/detection/results\"\n",
    "get_cv_metrics(X=X, y=y, scoring=scoring, voting_classifier=True, random_state=seed, epochs=epochs, cv=folds,\n",
    "               results_file_path=saved_results_path, model_file_path=saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cbd56a",
   "metadata": {},
   "source": [
    "And now let us check the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a10336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM_linear</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.738831</td>\n",
       "      <td>0.750903</td>\n",
       "      <td>0.732101</td>\n",
       "      <td>0.733536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM_rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.727707</td>\n",
       "      <td>0.733096</td>\n",
       "      <td>0.722859</td>\n",
       "      <td>0.723556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.670752</td>\n",
       "      <td>0.670278</td>\n",
       "      <td>0.669749</td>\n",
       "      <td>0.670092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>0.712427</td>\n",
       "      <td>0.716769</td>\n",
       "      <td>0.707991</td>\n",
       "      <td>0.708990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.732790</td>\n",
       "      <td>0.740454</td>\n",
       "      <td>0.727498</td>\n",
       "      <td>0.728113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 2000}</td>\n",
       "      <td>0.737511</td>\n",
       "      <td>0.741253</td>\n",
       "      <td>0.733509</td>\n",
       "      <td>0.733782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731096</td>\n",
       "      <td>0.778618</td>\n",
       "      <td>0.684094</td>\n",
       "      <td>0.610036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             params  accuracy  \\\n",
       "0  SVM_linear                                           {'C': 1}  0.738831   \n",
       "1     SVM_rbf                             {'C': 1, 'gamma': 0.1}  0.727707   \n",
       "2         MLP  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...  0.670752   \n",
       "3          DT                                   {'max_depth': 5}  0.712427   \n",
       "4          RF              {'max_depth': 5, 'n_estimators': 100}  0.732790   \n",
       "5          LR                       {'C': 0.1, 'max_iter': 2000}  0.737511   \n",
       "6          VC                                                NaN  0.731096   \n",
       "\n",
       "   precision_macro  f1_macro  recall_macro  \n",
       "0         0.750903  0.732101      0.733536  \n",
       "1         0.733096  0.722859      0.723556  \n",
       "2         0.670278  0.669749      0.670092  \n",
       "3         0.716769  0.707991      0.708990  \n",
       "4         0.740454  0.727498      0.728113  \n",
       "5         0.741253  0.733509      0.733782  \n",
       "6         0.778618  0.684094      0.610036  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_results=pd.read_csv(\"data/metrics/detection/results.tab\", sep='\\t', escapechar='\\\\')\n",
    "detection_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62b4355",
   "metadata": {},
   "source": [
    "### Prediction models (wave 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b475ed40",
   "metadata": {},
   "source": [
    "Repeat the same process for wave 5.\n",
    "\n",
    "Note that the two processes are independent, meaning that if we only want to train prediction models we cas skip the above section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccbd3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X_w5, y_w5\n",
    "\n",
    "# Load selected variables\n",
    "prediction_multisurf_variables = pd.read_csv(\"data/best_features/wave_5_features.tab\", sep='\\t', \n",
    "                                             escapechar='\\\\')['0'].tolist()\n",
    "X = X.loc[:, prediction_multisurf_variables]\n",
    "\n",
    "# Eliminate specific repeated features\n",
    "X.drop(list(X.filter(regex = 'ff.*')), axis = 1, inplace = True)\n",
    "\n",
    "# Select the best_grid_search features\n",
    "scoring = ['accuracy', 'precision_macro', 'f1_macro', 'recall_macro']\n",
    "folds = 10\n",
    "seed = 10\n",
    "epochs = 1000\n",
    "\n",
    "# Train models and save results\n",
    "saved_model_path = \"data/models/prediction/model\"\n",
    "saved_results_path = \"data/metrics/prediction/results\"\n",
    "get_cv_metrics(X=X, y=y, scoring=scoring, voting_classifier=True, random_state=seed, epochs=epochs, cv=folds,\n",
    "               results_file_path=saved_results_path, model_file_path=saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855caa34",
   "metadata": {},
   "source": [
    "Let us check the results that we just saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "049a6909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM_linear</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.738831</td>\n",
       "      <td>0.750903</td>\n",
       "      <td>0.732101</td>\n",
       "      <td>0.733536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM_rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.727707</td>\n",
       "      <td>0.733096</td>\n",
       "      <td>0.722859</td>\n",
       "      <td>0.723556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.670752</td>\n",
       "      <td>0.670278</td>\n",
       "      <td>0.669749</td>\n",
       "      <td>0.670092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>0.712427</td>\n",
       "      <td>0.716769</td>\n",
       "      <td>0.707991</td>\n",
       "      <td>0.708990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.732790</td>\n",
       "      <td>0.740454</td>\n",
       "      <td>0.727498</td>\n",
       "      <td>0.728113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 2000}</td>\n",
       "      <td>0.737511</td>\n",
       "      <td>0.741253</td>\n",
       "      <td>0.733509</td>\n",
       "      <td>0.733782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731096</td>\n",
       "      <td>0.778618</td>\n",
       "      <td>0.684094</td>\n",
       "      <td>0.610036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             params  accuracy  \\\n",
       "0  SVM_linear                                           {'C': 1}  0.738831   \n",
       "1     SVM_rbf                             {'C': 1, 'gamma': 0.1}  0.727707   \n",
       "2         MLP  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...  0.670752   \n",
       "3          DT                                   {'max_depth': 5}  0.712427   \n",
       "4          RF              {'max_depth': 5, 'n_estimators': 100}  0.732790   \n",
       "5          LR                       {'C': 0.1, 'max_iter': 2000}  0.737511   \n",
       "6          VC                                                NaN  0.731096   \n",
       "\n",
       "   precision_macro  f1_macro  recall_macro  \n",
       "0         0.750903  0.732101      0.733536  \n",
       "1         0.733096  0.722859      0.723556  \n",
       "2         0.670278  0.669749      0.670092  \n",
       "3         0.716769  0.707991      0.708990  \n",
       "4         0.740454  0.727498      0.728113  \n",
       "5         0.741253  0.733509      0.733782  \n",
       "6         0.778618  0.684094      0.610036  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_results=pd.read_csv(\"data/metrics/detection/results.tab\", sep='\\t', escapechar='\\\\')\n",
    "prediction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c99083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
